---
advertiser: ""
amazon_music: https://music.amazon.com/podcasts/c35a09fe-4116-4e04-8f68-77d61b112e46/episodes/f17b6e8b-d2c8-41de-92d6-1b50b808b411/engineering-kiosk-249-resilience-engineering-rate-limiting-oder-wie-429-dein-system-rettet
apple_podcasts: https://podcasts.apple.com/us/podcast/249-resilience-engineering-rate-limiting-oder-wie-429/id1603082924?i=1000743908994&uo=4
audio: https://audio1.redcircle.com/episodes/106dab62-e035-422a-a7e9-2af6b75b08ff/stream.mp3
chapter:
- start: 00:00:00
  title: "Resilience Engineering: Rate Limiting"
- start: 00:03:57
  title: "Failure Modes: Retry Storms, Thundering Herd, Traffic Spikes und Traffic Amplification"
- start: 00:04:28
  title: Info/Werbung
- start: 00:05:28
  title: "Failure Modes: Retry Storms, Thundering Herd, Traffic Spikes und Traffic Amplification"
- start: 00:17:50
  title: "Wo platzierst du Rate Limiting: Client, Edge, API Gateway, Sidecar und Ressourcen"
- start: 00:25:22
  title: "Welche Strategie passt: Bursts, Fairness und stateful vs stateless Rate Limiting"
- start: 00:28:54
  title: "Algorithmen: Fixed Window, Sliding Window, Token Bucket und Leaky Bucket"
- start: 00:38:36
  title: "Kommunikation: Rate Limits sauber kommunizieren und HTTP Header"
- start: 00:44:23
  title: "Wenn der Rate Limiter ausf√§llt: Fail Open vs Fail Closed"
- start: 00:50:28
  title: "Warum GraphQL Rate Limiting schwer ist: Query Kosten"
- start: 00:59:24
  title: "Takeaways: Rate Limiting als Sicherheitsgurt fuer Resilience und Verf√ºgbarkeit"
deezer: https://www.deezer.com/episode/829458382
description: "Rate Limiting klingt erstmal wie ein nerviges Nein. In Wahrheit ist es oft der Unterschied zwischen stabiler Plattform und dem Klassiker: kurz ein bisschen Traffic, und pl√∂tzlich ist alles down. Denn Systeme scheitern selten an einem Request, sondern fast immer an zu vielen: Retry Storms nach einem Funkloch, Thundering Herd nach einem Cache-Expire, Traffic Amplification in Microservices oder einfach ein Tenant, der als Noisy Neighbor das ganze Haus wachklingelt. In dieser Episode gehen wir gemeinsam tief ins Reliability- und Resilience-Engineering und bauen Rate Limiting von Grund auf. Wir kl√§ren, wozu Rate Limiting wirklich da ist, wie es sich von Back Pressure, Graceful Degradation, Fault Isolation und Load Shedding abgrenzt und wo du es in deiner Architektur verankerst: Client, Edge, API Gateway, Sidecar Proxy wie Envoy oder direkt an Ressourcen wie Datenbanken und Queues. Dann wird es konkret: Wir vergleichen die g√§ngigen Strategien und Algorithmen, Fixed Window, Sliding Window, Token Bucket und Leaky Bucket, inklusive Bursts, Fairness und der Frage stateful vs. stateless. Dazu kommt die Realit√§t: Was machst du, wenn der Rate Limiter selbst ausf√§llt ‚Äì Fail Open vs. Fail Closed ‚Äì, und warum das nicht nur Technik ist, sondern auch Produktmanagement, Monetarisierung und Kundenerlebnis. Als Bonus schauen wir auf Best Practices aus der Praxis: wie GitHub und Cloudflare Rate Limits via HTTP-Header kommunizieren, warum standardisierte Header gerade wieder Fahrt aufnehmen und wieso Rate Limiting bei GraphQL-APIs so schnell zur Kostenberechnung im Query-AST wird. Wenn du danach dein System nicht nur schneller, sondern auch stressresistenter machen willst, bist du hier richtig. Und ja, ein resilientes System darf auch mal Nein sagen, damit es morgen wieder Ja sagen kann. Bonus: Manchmal ist der beste Load Test ein einzelner Curl-Befehl zur falschen Zeit.  Unsere aktuellen Werbepartner findest du auf https://engineeringkiosk.dev/partners  Das schnelle Feedback zur Episode: üëç (top)\u00a0üëé (geht so)  Anregungen, Gedanken, Themen und W√ºnscheDein Feedback z√§hlt! Erreiche uns √ºber einen der folgenden Kan√§le ‚Ä¶ EngKiosk Community: https://engineeringkiosk.dev/join-discord\u00a0LinkedIn: https://www.linkedin.com/company/engineering-kiosk/Email: stehtisch@engineeringkiosk.devMastodon: https://podcasts.social/@engkioskBluesky: https://bsky.app/profile/engineeringkiosk.bsky.socialInstagram: https://www.instagram.com/engineeringkiosk/ Unterst√ºtze den Engineering KioskWenn du uns etwas Gutes tun m√∂chtest ‚Ä¶ Kaffee schmeckt uns immer\u00a0 Buy us a coffee: https://engineeringkiosk.dev/kaffee LinksEngineering Kiosk Episode #204 Resilience Engineering: Timeouts, Jitter, Backoff & andere Systemretter: https://engineeringkiosk.dev/podcast/episode/204-resilience-engineering-timeouts-jitter-backoff-andere-systemretter/Engineering Kiosk Episode #223 Throw redundancy at the tail: Request Hedging bei Google & Co.: https://engineeringkiosk.dev/podcast/episode/223-throw-redundancy-at-the-tail-request-hedging-bei-google-co/GitHub Rate Limits: https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28GitHub Rate Limit Header: https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28#checking-the-status-of-your-rate-limitCloudflare Rate Limit Header: https://developers.cloudflare.com/fundamentals/api/reference/limits/#rate-limiting-headersGitHub Rate limits and query limits for the GraphQL API: https://docs.github.com/en/graphql/overview/rate-limits-and-query-limits-for-the-graphql-apiIETF Datatracker - RateLimit header fields for HTTP: https://datatracker.ietf.org/doc/draft-ietf-httpapi-ratelimit-headers/Engineering Kiosk Episode #212 Multi-Tenant done right: Isolationsmodelle, Cell-Based-Architecture, Shuffle Sharding & Co mit Maximilian Schellhorn: https://engineeringkiosk.dev/podcast/episode/212-multi-tenant-done-right-isolationsmodelle-cell-based-architecture-shuffle-sharding-co-mit-maximilian-schellhorn/ Sprungmarken(00:00:00) Resilience Engineering: Rate Limiting (00:03:57) Failure Modes: Retry Storms, Thundering Herd, Traffic Spikes und Traffic Amplification (00:04:28) Info/Werbung (00:05:28) Failure Modes: Retry Storms, Thundering Herd, Traffic Spikes und Traffic Amplification (00:17:50) Wo platzierst du Rate Limiting: Client, Edge, API Gateway, Sidecar und Ressourcen (00:25:22) Welche Strategie passt: Bursts, Fairness und stateful vs stateless Rate Limiting (00:28:54) Algorithmen: Fixed Window, Sliding Window, Token Bucket und Leaky Bucket (00:38:36) Kommunikation: Rate Limits sauber kommunizieren und HTTP Header (00:44:23) Wenn der Rate Limiter ausf√§llt: Fail Open vs Fail Closed (00:50:28) Warum GraphQL Rate Limiting schwer ist: Query Kosten (00:59:24) Takeaways: Rate Limiting als Sicherheitsgurt fuer Resilience und Verf√ºgbarkeit  HostsWolfgang Gassler (https://gassler.dev)\u00a0Andy Grunwald (https://andygrunwald.com/) CommunityDiskutiere mit uns und vielen anderen Tech-Spezialist‚ãÖinnen in unserer Engineering Kiosk Community unter https://engineeringkiosk.dev/join-discord"
headlines: anregungen-gedanken-themen-und-w√ºnsche::Anregungen, Gedanken, Themen und W√ºnsche||unterst√ºtze-den-engineering-kiosk::Unterst√ºtze den Engineering Kiosk||links::Links||sprungmarken::Sprungmarken||hosts::Hosts||community::Community
image: ./249-resilience-engineering-rate-limiting-oder-wie-429-dein-system-rettet.jpg
length_second: 3852
pubDate: 2026-01-06 02:00:33+00:00
speaker:
- name: Andy Grunwald
  transcriptLetter: A
- name: Wolfi Gassler
  transcriptLetter: B
spotify: https://open.spotify.com/episode/4ikBG6gv6jlYNfsLBkbbdh
tags:
- DevOps
- Software Engineering
- Engineering Kiosk
title: "#249 Resilience Engineering: Rate Limiting oder wie 429 dein System rettet"
transcript_slim: ""
youtube: https://www.youtube.com/watch?v=opho_2o0WgI
---
<p>Rate Limiting klingt erstmal wie ein nerviges Nein. In Wahrheit ist es oft der Unterschied zwischen stabiler Plattform und dem Klassiker: kurz ein bisschen Traffic, und pl√∂tzlich ist alles down. Denn Systeme scheitern selten an einem Request, sondern fast immer an zu vielen: Retry Storms nach einem Funkloch, Thundering Herd nach einem Cache-Expire, Traffic Amplification in Microservices oder einfach ein Tenant, der als Noisy Neighbor das ganze Haus wachklingelt.</p><p>In dieser Episode gehen wir gemeinsam tief ins Reliability- und Resilience-Engineering und bauen Rate Limiting von Grund auf. Wir kl√§ren, wozu Rate Limiting wirklich da ist, wie es sich von Back Pressure, Graceful Degradation, Fault Isolation und Load Shedding abgrenzt und wo du es in deiner Architektur verankerst: Client, Edge, API Gateway, Sidecar Proxy wie Envoy oder direkt an Ressourcen wie Datenbanken und Queues.</p><p>Dann wird es konkret: Wir vergleichen die g√§ngigen Strategien und Algorithmen, Fixed Window, Sliding Window, Token Bucket und Leaky Bucket, inklusive Bursts, Fairness und der Frage stateful vs. stateless. Dazu kommt die Realit√§t: Was machst du, wenn der Rate Limiter selbst ausf√§llt ‚Äì Fail Open vs. Fail Closed ‚Äì, und warum das nicht nur Technik ist, sondern auch Produktmanagement, Monetarisierung und Kundenerlebnis.</p><p>Als Bonus schauen wir auf Best Practices aus der Praxis: wie GitHub und Cloudflare Rate Limits via HTTP-Header kommunizieren, warum standardisierte Header gerade wieder Fahrt aufnehmen und wieso Rate Limiting bei GraphQL-APIs so schnell zur Kostenberechnung im Query-AST wird.</p><p>Wenn du danach dein System nicht nur schneller, sondern auch stressresistenter machen willst, bist du hier richtig. Und ja, ein resilientes System darf auch mal Nein sagen, damit es morgen wieder Ja sagen kann.</p><p>Bonus: Manchmal ist der beste Load Test ein einzelner Curl-Befehl zur falschen Zeit.</p><p><br></p><p>Unsere aktuellen Werbepartner findest du auf <a href="https://engineeringkiosk.dev/partners">https://engineeringkiosk.dev/partners</a></p><p><br></p><p><strong>Das schnelle Feedback zur Episode:</strong></p><p><a href="https://api.openpodcast.dev/feedback/249/upvote" rel="nofollow"><strong>üëç (top)</strong></a><strong>¬†</strong><a href="https://api.openpodcast.dev/feedback/249/downvote" rel="nofollow"><strong>üëé (geht so)</strong></a></p><p><br></p><h3 id="anregungen-gedanken-themen-und-w√ºnsche">Anregungen, Gedanken, Themen und W√ºnsche</h3><p>Dein Feedback z√§hlt! Erreiche uns √ºber einen der folgenden Kan√§le ‚Ä¶</p><ul><li>EngKiosk Community: <a href="https://engineeringkiosk.dev/join-discord">https://engineeringkiosk.dev/join-discord</a>¬†</li><li>LinkedIn: <a href="https://www.linkedin.com/company/engineering-kiosk/" rel="nofollow">https://www.linkedin.com/company/engineering-kiosk/</a></li><li>Email: <a href="mailto:stehtisch@engineeringkiosk.dev" rel="nofollow">stehtisch@engineeringkiosk.dev</a></li><li>Mastodon: <a href="https://podcasts.social/@engkiosk" rel="nofollow">https://podcasts.social/@engkiosk</a></li><li>Bluesky: <a href="https://bsky.app/profile/engineeringkiosk.bsky.social" rel="nofollow">https://bsky.app/profile/engineeringkiosk.bsky.social</a></li><li>Instagram: <a href="https://www.instagram.com/engineeringkiosk/" rel="nofollow">https://www.instagram.com/engineeringkiosk/</a></li></ul><p><br></p><h3 id="unterst√ºtze-den-engineering-kiosk">Unterst√ºtze den Engineering Kiosk</h3><p>Wenn du uns etwas Gutes tun m√∂chtest ‚Ä¶ Kaffee schmeckt uns immer¬†</p><ul><li>Buy us a coffee: <a href="https://engineeringkiosk.dev/kaffee">https://engineeringkiosk.dev/kaffee</a></li></ul><p><br></p><h3 id="links">Links</h3><ul><li>Engineering Kiosk Episode #204 Resilience Engineering: Timeouts, Jitter, Backoff &amp; andere Systemretter: <a href="https://engineeringkiosk.dev/podcast/episode/204-resilience-engineering-timeouts-jitter-backoff-andere-systemretter/">https://engineeringkiosk.dev/podcast/episode/204-resilience-engineering-timeouts-jitter-backoff-andere-systemretter/</a></li><li>Engineering Kiosk Episode #223 Throw redundancy at the tail: Request Hedging bei Google &amp; Co.: <a href="https://engineeringkiosk.dev/podcast/episode/223-throw-redundancy-at-the-tail-request-hedging-bei-google-co/">https://engineeringkiosk.dev/podcast/episode/223-throw-redundancy-at-the-tail-request-hedging-bei-google-co/</a></li><li>GitHub Rate Limits: <a href="https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28" rel="nofollow">https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28</a></li><li>GitHub Rate Limit Header: <a href="https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28#checking-the-status-of-your-rate-limit" rel="nofollow">https://docs.github.com/en/rest/using-the-rest-api/rate-limits-for-the-rest-api?apiVersion=2022-11-28#checking-the-status-of-your-rate-limit</a></li><li>Cloudflare Rate Limit Header: <a href="https://developers.cloudflare.com/fundamentals/api/reference/limits/#rate-limiting-headers" rel="nofollow">https://developers.cloudflare.com/fundamentals/api/reference/limits/#rate-limiting-headers</a></li><li>GitHub Rate limits and query limits for the GraphQL API: <a href="https://docs.github.com/en/graphql/overview/rate-limits-and-query-limits-for-the-graphql-api" rel="nofollow">https://docs.github.com/en/graphql/overview/rate-limits-and-query-limits-for-the-graphql-api</a></li><li>IETF Datatracker - RateLimit header fields for HTTP: <a href="https://datatracker.ietf.org/doc/draft-ietf-httpapi-ratelimit-headers/" rel="nofollow">https://datatracker.ietf.org/doc/draft-ietf-httpapi-ratelimit-headers/</a></li><li>Engineering Kiosk Episode #212 Multi-Tenant done right: Isolationsmodelle, Cell-Based-Architecture, Shuffle Sharding &amp; Co mit Maximilian Schellhorn: <a href="https://engineeringkiosk.dev/podcast/episode/212-multi-tenant-done-right-isolationsmodelle-cell-based-architecture-shuffle-sharding-co-mit-maximilian-schellhorn/">https://engineeringkiosk.dev/podcast/episode/212-multi-tenant-done-right-isolationsmodelle-cell-based-architecture-shuffle-sharding-co-mit-maximilian-schellhorn/</a></li></ul><p><br></p><h3 id="sprungmarken">Sprungmarken</h3><p>(00:00:00) Resilience Engineering: Rate Limiting</p><p>(00:03:57) Failure Modes: Retry Storms, Thundering Herd, Traffic Spikes und Traffic Amplification</p><p>(00:04:28) Info/Werbung</p><p>(00:05:28) Failure Modes: Retry Storms, Thundering Herd, Traffic Spikes und Traffic Amplification</p><p>(00:17:50) Wo platzierst du Rate Limiting: Client, Edge, API Gateway, Sidecar und Ressourcen</p><p>(00:25:22) Welche Strategie passt: Bursts, Fairness und stateful vs stateless Rate Limiting</p><p>(00:28:54) Algorithmen: Fixed Window, Sliding Window, Token Bucket und Leaky Bucket</p><p>(00:38:36) Kommunikation: Rate Limits sauber kommunizieren und HTTP Header</p><p>(00:44:23) Wenn der Rate Limiter ausf√§llt: Fail Open vs Fail Closed</p><p>(00:50:28) Warum GraphQL Rate Limiting schwer ist: Query Kosten</p><p>(00:59:24) Takeaways: Rate Limiting als Sicherheitsgurt fuer Resilience und Verf√ºgbarkeit</p><p><br></p><h3 id="hosts">Hosts</h3><ul><li>Wolfgang Gassler (<a href="https://gassler.dev" rel="nofollow">https://gassler.dev</a>)¬†</li><li>Andy Grunwald (<a href="https://andygrunwald.com/" rel="nofollow">https://andygrunwald.com/</a>)</li></ul><p><br></p><h3 id="community">Community</h3><p>Diskutiere mit uns und vielen anderen Tech-Spezialist‚ãÖinnen in unserer Engineering Kiosk Community unter <a href="https://engineeringkiosk.dev/join-discord">https://engineeringkiosk.dev/join-discord</a> </p>