---
advertiser: ''
amazon_music: https://music.amazon.com/podcasts/c35a09fe-4116-4e04-8f68-77d61b112e46/episodes/e36742ba-b7f8-456f-b44f-5c9e027ad855/engineering-kiosk-184-gpu-programmierung---von-cuda-bis-openmp-mit-peter-thoman
apple_podcasts: https://podcasts.apple.com/us/podcast/184-gpu-programmierung-von-cuda-bis-openmp-mit-peter-thoman/id1603082924?i=1000695729082&uo=4
audio: https://audio1.redcircle.com/episodes/bea196a3-54d1-4909-a540-fe20f245a0aa/stream.mp3
chapter:
- start: 00:00:00
  title: Intro
- start: 00:01:28
  title: Paralleles Programmieren auf der GPU mit Peter Thoman
- start: 00:07:26
  title: Was ist was? Verteiltes vs. paralleles Rechnen, HPC, CUDA und mehr
- start: 00:08:34
  title: Info/Werbung
- start: 00:09:34
  title: Was ist was? Verteiltes vs. paralleles Rechnen, HPC, CUDA und mehr
- start: 00:22:34
  title: Wie hat die Berechnung auf der GPU begonnen?
- start: 00:33:23
  title: "Use-Cases f\xFCr die GPU"
- start: 00:45:58
  title: Matrizenmultiplikation und Neuronale Netze auf der GPU
- start: 00:55:11
  title: "Heterogenit\xE4t der Grafikkarten und Chips"
- start: 01:00:10
  title: Dein Einstieg in die GPU-Programmierung
deezer: https://www.deezer.com/episode/722573271
description: "GPU-Programmierung: Andere Chips und eine andere Art zu programmieren\
  \ In der heutigen Zeit dreht sich fast alles in der IT um AI. Und damit auch oft\
  \ um den sich positiv entwickelnden Aktienkurs von Nvidia. Warum Nvidia? Als Hersteller\
  \ von Grafikkarten bzw. Grafikchips (kurz GPUs) profitieren sie deutlich von den\
  \ hohen Nachfragen nach dieser Art von Chips. Das Ganze hat die Frage aufgeworfen:\
  \ Inwieweit ist die Programmierung auf bzw. f\xFCr eine GPU anders als bei einer\
  \ klassischen CPU? In dieser Episode behandeln wir dieses Thema: Paralleles Programmieren\
  \ auf der GPU. Wir br\xF6seln das Buzzword-Bingo auf und schauen uns an, was der\
  \ Unterschied zu verteiltem vs. parallelem Rechnen ist, was HPC und CUDA eigentlich\
  \ ist, ob bzw. wie man auf Grafikkarten ohne Frameworks programmieren kann, welche\
  \ algorithmischen Use Cases neben AI und Transformer-Modelle existieren, wie man\
  \ einen Algorithmus f\xFCr die GPU programmiert und was man alles vermeiden sollte,\
  \ sprechen \xFCber Speicherzugriffsmuster und warum Matrizen-Multiplikationen so\
  \ gut auf GPUs funktionieren aber auch was Performance-Portabilit\xE4t bedeutet\
  \ und ob es Probleme mit der Heterogenit\xE4t von Grafikkarten und Chips gibt. Und\
  \ das alles mit Dr. Prof. Peter Thoman. Bonus: Wie besucht man m\xF6glichst effizient\
  \ alle St\xE4dte in Deutschland? Das Problem des Handlungsreisenden.  Unsere aktuellen\
  \ Werbepartner findest du auf https://engineeringkiosk.dev/partners  Das schnelle\
  \ Feedback zur Episode: \U0001F44D (top)\_\U0001F44E (geht so)  FeedbackEngKiosk\
  \ Community: https://engineeringkiosk.dev/join-discord\_Buy us a coffee: https://engineeringkiosk.dev/kaffeeEmail:\
  \ stehtisch@engineeringkiosk.devLinkedIn: https://www.linkedin.com/company/engineering-kiosk/Mastodon:\
  \ https://podcasts.social/@engkioskBluesky: https://bsky.app/profile/engineeringkiosk.bsky.socialTwitter:\
  \ https://twitter.com/EngKiosk LinksDr. Peter Thoman: https://dps.uibk.ac.at/~petert/PH3\
  \ GmbH: https://www.ph3.at\_SimSYCL: https://github.com/celerity/SimSYCL\_Celerity:\
  \ https://celerity.github.io/CUDA: https://developer.nvidia.com/cuda-toolkitWas\
  \ ist CUDA: https://www.bigdata-insider.de/was-ist-cuda-a-851005/OpenMP: https://www.openmp.org/OpenMPI:\
  \ https://www.open-mpi.org/OpenGL: https://www.opengl.org/OpenCL: https://www.khronos.org/opencl/Engineering\
  \ Kiosk Episode #180 Skalierung, aber zu welchem Preis? (Papers We Love): https://engineeringkiosk.dev/podcast/episode/180-skalierung-aber-zu-welchem-preis-papers-we-love/Nvidia\
  \ Self-Paced Training: https://learn.nvidia.com/en-us/training/self-paced-coursesSYCL\
  \ Academy: https://github.com/codeplaysoftware/syclacademy Sprungmarken(00:00:00)\
  \ Intro (00:01:28) Paralleles Programmieren auf der GPU mit Peter Thoman (00:07:26)\
  \ Was ist was? Verteiltes vs. paralleles Rechnen, HPC, CUDA und mehr (00:08:34)\
  \ Info/Werbung (00:09:34) Was ist was? Verteiltes vs. paralleles Rechnen, HPC, CUDA\
  \ und mehr (00:22:34) Wie hat die Berechnung auf der GPU begonnen? (00:33:23) Use-Cases\
  \ f\xFCr die GPU (00:45:58) Matrizenmultiplikation und Neuronale Netze auf der GPU\
  \ (00:55:11) Heterogenit\xE4t der Grafikkarten und Chips (01:00:10) Dein Einstieg\
  \ in die GPU-Programmierung  HostsWolfgang Gassler (https://gassler.dev)\_Andy Grunwald\
  \ (https://andygrunwald.com/) FeedbackEngKiosk Community: https://engineeringkiosk.dev/join-discord\_\
  Buy us a coffee: https://engineeringkiosk.dev/kaffeeEmail: stehtisch@engineeringkiosk.devLinkedIn:\
  \ https://www.linkedin.com/company/engineering-kiosk/Mastodon: https://podcasts.social/@engkioskBluesky:\
  \ https://bsky.app/profile/engineeringkiosk.bsky.socialTwitter: https://twitter.com/EngKiosk"
headlines: feedback::Feedback||links::Links||sprungmarken::Sprungmarken||hosts::Hosts
image: ./184-gpu-programmierung-von-cuda-bis-openmp-mit-peter-thoman.jpg
length_second: 4279
pubDate: 2025-02-25 05:00:00+00:00
rtlplus: ''
six_user_needs: []
speaker:
- name: Andy Grunwald
  transcriptLetter: B
- name: Wolfi Gassler
  transcriptLetter: A
- name: Peter Thoman
  transcriptLetter: C
spotify: https://open.spotify.com/episode/69t13TF9kXbJPAOQVapRT7
tags:
- Backend
- Software Engineering
- Interview
title: '#184 GPU Programmierung - von CUDA bis OpenMP mit Peter Thoman'
transcript_raw: ''
transcript_slim: src/data/transcripts/184-transcript-slim.json
youtube: https://www.youtube.com/watch?v=jyEgOn4NL3g

---
<p>GPU-Programmierung: Andere Chips und eine andere Art zu programmieren</p><p>In der heutigen Zeit dreht sich fast alles in der IT um AI. Und damit auch oft um den sich positiv entwickelnden Aktienkurs von Nvidia. Warum Nvidia? Als Hersteller von Grafikkarten bzw. Grafikchips (kurz GPUs) profitieren sie deutlich von den hohen Nachfragen nach dieser Art von Chips. Das Ganze hat die Frage aufgeworfen: Inwieweit ist die Programmierung auf bzw. f√ºr eine GPU anders als bei einer klassischen CPU?</p><p>In dieser Episode behandeln wir dieses Thema: Paralleles Programmieren auf der GPU.</p><p>Wir br√∂seln das Buzzword-Bingo auf und schauen uns an, was der Unterschied zu verteiltem vs. parallelem Rechnen ist, was HPC und CUDA eigentlich ist, ob bzw. wie man auf Grafikkarten ohne Frameworks programmieren kann, welche algorithmischen Use Cases neben AI und Transformer-Modelle existieren, wie man einen Algorithmus f√ºr die GPU programmiert und was man alles vermeiden sollte, sprechen √ºber Speicherzugriffsmuster und warum Matrizen-Multiplikationen so gut auf GPUs funktionieren aber auch was Performance-Portabilit√§t bedeutet und ob es Probleme mit der Heterogenit√§t von Grafikkarten und Chips gibt.</p><p>Und das alles mit Dr. Prof. Peter Thoman.</p><p>Bonus: Wie besucht man m√∂glichst effizient alle St√§dte in Deutschland? Das Problem des Handlungsreisenden.</p><p><br></p><p>Unsere aktuellen Werbepartner findest du auf <a href="https://engineeringkiosk.dev/partners">https://engineeringkiosk.dev/partners</a></p><p><br></p><p><strong>Das schnelle Feedback zur Episode:</strong></p><p><a href="https://api.openpodcast.dev/feedback/184/upvote" rel="nofollow"><strong>üëç (top)</strong></a><strong>¬†</strong><a href="https://api.openpodcast.dev/feedback/184/downvote" rel="nofollow"><strong>üëé (geht so)</strong></a></p><p><br></p><h3 id="feedback">Feedback</h3><ul><li>EngKiosk Community: <a href="https://engineeringkiosk.dev/join-discord">https://engineeringkiosk.dev/join-discord</a>¬†</li><li>Buy us a coffee: <a href="https://engineeringkiosk.dev/kaffee">https://engineeringkiosk.dev/kaffee</a></li><li>Email: <a href="mailto:stehtisch@engineeringkiosk.dev" rel="nofollow">stehtisch@engineeringkiosk.dev</a></li><li>LinkedIn: <a href="https://www.linkedin.com/company/engineering-kiosk/" rel="nofollow">https://www.linkedin.com/company/engineering-kiosk/</a></li><li>Mastodon: <a href="https://podcasts.social/@engkiosk" rel="nofollow">https://podcasts.social/@engkiosk</a></li><li>Bluesky: <a href="https://bsky.app/profile/engineeringkiosk.bsky.social" rel="nofollow">https://bsky.app/profile/engineeringkiosk.bsky.social</a></li><li>Twitter: <a href="https://twitter.com/EngKiosk" rel="nofollow">https://twitter.com/EngKiosk</a></li></ul><p><br></p><h3 id="links">Links</h3><ul><li>Dr. Peter Thoman: <a href="https://dps.uibk.ac.at/~petert/" rel="nofollow">https://dps.uibk.ac.at/~petert/</a></li><li>PH3 GmbH: <a href="https://www.ph3.at" rel="nofollow">https://www.ph3.at</a>¬†</li><li>SimSYCL: <a href="https://github.com/celerity/SimSYCL" rel="nofollow">https://github.com/celerity/SimSYCL</a>¬†</li><li>Celerity: <a href="https://celerity.github.io/" rel="nofollow">https://celerity.github.io/</a></li><li>CUDA: <a href="https://developer.nvidia.com/cuda-toolkit" rel="nofollow">https://developer.nvidia.com/cuda-toolkit</a></li><li>Was ist CUDA: <a href="https://www.bigdata-insider.de/was-ist-cuda-a-851005/" rel="nofollow">https://www.bigdata-insider.de/was-ist-cuda-a-851005/</a></li><li>OpenMP: <a href="https://www.openmp.org/" rel="nofollow">https://www.openmp.org/</a></li><li>OpenMPI: <a href="https://www.open-mpi.org/" rel="nofollow">https://www.open-mpi.org/</a></li><li>OpenGL: <a href="https://www.opengl.org/" rel="nofollow">https://www.opengl.org/</a></li><li>OpenCL: <a href="https://www.khronos.org/opencl/" rel="nofollow">https://www.khronos.org/opencl/</a></li><li>Engineering Kiosk Episode #180 Skalierung, aber zu welchem Preis? (Papers We Love): <a href="https://engineeringkiosk.dev/podcast/episode/180-skalierung-aber-zu-welchem-preis-papers-we-love/">https://engineeringkiosk.dev/podcast/episode/180-skalierung-aber-zu-welchem-preis-papers-we-love/</a></li><li>Nvidia Self-Paced Training: <a href="https://learn.nvidia.com/en-us/training/self-paced-courses" rel="nofollow">https://learn.nvidia.com/en-us/training/self-paced-courses</a></li><li>SYCL Academy: <a href="https://github.com/codeplaysoftware/syclacademy" rel="nofollow">https://github.com/codeplaysoftware/syclacademy</a></li></ul><p><br></p><h3 id="sprungmarken">Sprungmarken</h3><p>(00:00:00) Intro</p><p>(00:01:28) Paralleles Programmieren auf der GPU mit Peter Thoman</p><p>(00:07:26) Was ist was? Verteiltes vs. paralleles Rechnen, HPC, CUDA und mehr</p><p>(00:08:34) Info/Werbung</p><p>(00:09:34) Was ist was? Verteiltes vs. paralleles Rechnen, HPC, CUDA und mehr</p><p>(00:22:34) Wie hat die Berechnung auf der GPU begonnen?</p><p>(00:33:23) Use-Cases f√ºr die GPU</p><p>(00:45:58) Matrizenmultiplikation und Neuronale Netze auf der GPU</p><p>(00:55:11) Heterogenit√§t der Grafikkarten und Chips</p><p>(01:00:10) Dein Einstieg in die GPU-Programmierung</p><p><br></p><h3 id="hosts">Hosts</h3><ul><li>Wolfgang Gassler (<a href="https://gassler.dev" rel="nofollow">https://gassler.dev</a>)¬†</li><li>Andy Grunwald (<a href="https://andygrunwald.com/" rel="nofollow">https://andygrunwald.com/</a>)</li></ul><p><br></p><h3 id="feedback">Feedback</h3><ul><li>EngKiosk Community: <a href="https://engineeringkiosk.dev/join-discord">https://engineeringkiosk.dev/join-discord</a>¬†</li><li>Buy us a coffee: <a href="https://engineeringkiosk.dev/kaffee">https://engineeringkiosk.dev/kaffee</a></li><li>Email: <a href="mailto:stehtisch@engineeringkiosk.dev" rel="nofollow">stehtisch@engineeringkiosk.dev</a></li><li>LinkedIn: <a href="https://www.linkedin.com/company/engineering-kiosk/" rel="nofollow">https://www.linkedin.com/company/engineering-kiosk/</a></li><li>Mastodon: <a href="https://podcasts.social/@engkiosk" rel="nofollow">https://podcasts.social/@engkiosk</a></li><li>Bluesky: <a href="https://bsky.app/profile/engineeringkiosk.bsky.social" rel="nofollow">https://bsky.app/profile/engineeringkiosk.bsky.social</a></li><li>Twitter: <a href="https://twitter.com/EngKiosk" rel="nofollow">https://twitter.com/EngKiosk</a></li></ul>